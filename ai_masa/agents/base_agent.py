import sys
import json
import subprocess
import threading
import time
from ..models.message import Message
from ..comms.redis_broker import RedisBroker
from ..models.prompts import JSON_FORMAT_EXAMPLE, PROMPT_TEMPLATE, OBSERVER_INSTRUCTION

class BaseAgent:
    def __init__(self, name, description, user_lang='Japanese', redis_host='localhost',
                 llm_command="echo '{\"to_agent\": \"dummy\", \"content\": \"dummy response\"}'",
                 llm_session_create_command="echo 'new_session_id'",
                 start_heartbeat=True):
        self.name = name
        self.description = description
        self.user_lang = user_lang
        self.language = 'en' # LLMé–“ã®ä¼šè©±ã¯è‹±èªã«å›ºå®š
        self.llm_command = llm_command
        self.llm_session_create_command = llm_session_create_command
        
        # job_idã”ã¨ã«ä¼šè©±å±¥æ­´ã¨LLMã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç®¡ç†
        self.context = {}  # { "job_id_1": [msg1, msg2], "job_id_2": [msg3] }
        self.job_sessions = {} # { "job_id_1": "llm_session_uuid_a", "job_id_2": "llm_session_uuid_b" }
        
        self.broker = RedisBroker(host=redis_host)
        self.broker.connect()
        
        # ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹•çš„ã«ç”Ÿæˆ
        self.role_prompt = self._generate_role_prompt()

        # çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆã¨ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã®è¨­å®š
        self.shutdown_event = threading.Event()
        self.heartbeat_timer = None
        if start_heartbeat:
            self._start_heartbeat()

    def shutdown(self):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã—ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã™ã‚‹"""
        print(f"[{self.name}] Shutting down...")
        self.shutdown_event.set()
        if self.heartbeat_timer:
            self.heartbeat_timer.cancel()

    def _send_heartbeat(self):
        """ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã‚’é€ä¿¡ã™ã‚‹"""
        if self.shutdown_event.is_set():
            return
            
        # è‡ªåˆ†è‡ªèº«ã«ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆCCä»˜ãã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        self.broadcast(
            target=self.name, 
            content="heartbeat", 
            cc=["_broadcast_"],
            job_id="_system_"
        )
        
        # æ¬¡ã®ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        self.heartbeat_timer = threading.Timer(30, self._send_heartbeat)
        self.heartbeat_timer.start()

    def _start_heartbeat(self):
        """ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã®é€ä¿¡ã‚’é–‹å§‹ã™ã‚‹"""
        print(f"[{self.name}] Starting heartbeat...")
        # æœ€åˆã®ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆã‚’ã™ãã«é€ä¿¡
        self._send_heartbeat()

    def _generate_role_prompt(self):
        return f"""Your name is {self.name}. {self.description}
When you send a message to the 'User' agent, please respond in {self.user_lang}.
Your response must be a JSON object that adheres to the following format.
IMPORTANT: The 'to_agent' field must be the 'from_agent' of the message you are replying to.
Example:
```json
{JSON_FORMAT_EXAMPLE}
```
""".strip()

    def observe_loop(self):
        print(f"[{self.name}] Listening on Redis...")
        self.broker.subscribe(self._on_message_received, shutdown_event=self.shutdown_event)

    def _on_message_received(self, message_json):
        try:
            msg = Message.from_json(message_json)
            if msg.from_agent == self.name:
                return

            job_id = msg.job_id or "default"
            
            self.context.setdefault(job_id, []).append(msg)

            is_to_me = msg.to_agent == self.name
            if is_to_me:
                print(f"[{self.name}][{job_id}] ğŸ“¨ Received from {msg.from_agent}: {msg.content}")
                self.think_and_respond(msg, job_id)
            elif self.name in msg.cc_agents:
                print(f"[{self.name}][{job_id}] ğŸ‘€ (CC) Saw message from {msg.from_agent}")
                # CCã§å—ä¿¡ã—ãŸå ´åˆã‚‚ã€è¦³å¯Ÿè€…ã¨ã—ã¦æ€è€ƒã™ã‚‹
                self.think_and_respond(msg, job_id, is_observer=True)

        except Exception as e:
            print(f"[{self.name}] Error in _on_message_received: {e}")

    def think_and_respond(self, trigger_msg, job_id, is_observer=False):
        llm_session_id = self.job_sessions.get(job_id)
        
        if not llm_session_id:
            print(f"[{self.name}][{job_id}] No session found. Creating a new one...")
            llm_session_id = self._create_llm_session(job_id)
            if not llm_session_id:
                print(f"[{self.name}][{job_id}] Failed to create LLM session. Aborting.")
                return
            self.job_sessions[job_id] = llm_session_id
            print(f"[{self.name}][{job_id}] New session created: {llm_session_id}")

        prompt = self._build_prompt(trigger_msg, job_id, is_observer=is_observer)
        llm_response_json = self._invoke_llm(prompt, llm_session_id)
        
        if not llm_response_json:
            print(f"[{self.name}][{job_id}] Error: LLM did not return a response.")
            return

        try:
            response_data = json.loads(llm_response_json)
            self.broadcast(
                target=response_data.get("to_agent"),
                content=response_data.get("content"),
                cc=response_data.get("cc_agents"),
                job_id=job_id
            )
        except json.JSONDecodeError as e:
            print(f"[{self.name}][{job_id}] Error decoding LLM response: {e}\nReceived: {llm_response_json}")
        except Exception as e:
            print(f"[{self.name}][{job_id}] Error processing LLM response: {e}")

    def _create_llm_session(self, job_id):
        """æ–°ã—ã„LLMã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã€ãã®IDã‚’è¿”ã™"""
        print(f"[{self.name}][{job_id}] Initializing LLM session with role: {self.role_prompt}")
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆã‚³ãƒãƒ³ãƒ‰ã«ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦æ¸¡ã™
            process = subprocess.run(
                self.llm_session_create_command,
                input=self.role_prompt,
                capture_output=True, text=True, shell=True, check=True
            )
            # ã‚³ãƒãƒ³ãƒ‰ã®æ¨™æº–å‡ºåŠ›ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆæœ€å¾Œã®è¡Œãªã©ï¼‰ã‚’å–å¾—
            session_id = process.stdout.strip().split('\n')[-1]
            return session_id
        except subprocess.CalledProcessError as e:
            print(f"[{self.name}][{job_id}] Error executing LLM session creation command: {e}\nStderr: {e.stderr}")
            return None
        except FileNotFoundError:
            print(f"[{self.name}][{job_id}] Error: LLM command not found: '{self.llm_session_create_command}'")
            return None

    def _build_prompt(self, trigger_msg, job_id, is_observer=False):
        history = "\n".join([f"- {msg.from_agent}: {msg.content}" for msg in self.context.get(job_id, [])])
        
        observer_instructions = ""
        if is_observer:
            observer_instructions = OBSERVER_INSTRUCTION
            
        return PROMPT_TEMPLATE.format(
            name=self.name, 
            role_prompt=self.role_prompt,
            history=history,
            from_agent=trigger_msg.from_agent, 
            content=trigger_msg.content,
            observer_instructions=observer_instructions
        )

    def _invoke_llm(self, prompt, llm_session_id):
        print(f"[{self.name}][{self.job_sessions.get(llm_session_id, 'N/A')}] ğŸ§  Thinking...")
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å®Ÿéš›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã§ç½®æ›
        command_to_run = self.llm_command.format(session_id=llm_session_id)

        try:
            process = subprocess.run(
                command_to_run,
                input=prompt, capture_output=True, text=True, shell=True, check=True
            )
            raw_stdout = process.stdout
            
            # Gemini CLIã®å‡ºåŠ›å½¢å¼ã«å¯¾å¿œã™ã‚‹å‡¦ç†
            try:
                # ã¾ãšã€å¤–å´ã®JSONã‚’ãƒ‘ãƒ¼ã‚¹
                outer_response = json.loads(raw_stdout)
                if "response" in outer_response:
                    # 'response'ã‚­ãƒ¼ã®å€¤ï¼ˆMarkdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰ã‚’æŠ½å‡º
                    content_str = outer_response["response"]
                    # Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONæ–‡å­—åˆ—ã‚’æŠ½å‡º
                    if content_str.strip().startswith("```json"):
                        json_start = content_str.find("{")
                        json_end = content_str.rfind("}") + 1
                        if json_start != -1 and json_end != -1:
                            inner_json_str = content_str[json_start:json_end]
                            # å†…éƒ¨ã®JSONæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦è¿”ã™
                            return json.dumps(json.loads(inner_json_str))
                # 'response'ã‚­ãƒ¼ãŒãªã„ã‹ã€ã¾ãŸã¯JSONã¨ã—ã¦å‡¦ç†ã§ããªã‹ã£ãŸå ´åˆã€å…ƒã®stdoutã‚’è¿”ã™
                return raw_stdout
            except json.JSONDecodeError:
                # å¤–å´ã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€ãã®ã¾ã¾è¿”ã™ (æ—¢å­˜ã®æŒ™å‹•)
                return raw_stdout
        except subprocess.CalledProcessError as e:
            print(f"[{self.name}] Error executing LLM command: {e}\nStderr: {e.stderr}")
            return None
        except FileNotFoundError:
            print(f"[{self.name}] Error: LLM command not found: '{command_to_run}'")
            return None

    def broadcast(self, target, content, cc=None, job_id="default"):
        if not target or not content:
            print(f"[{self.name}][{job_id}] âš ï¸ Missing target or content. Aborting broadcast.")
            return
        msg = Message(self.name, target, content, cc_agents=cc, job_id=job_id)
        self.broker.publish(msg.to_json())
        print(f"[{self.name}][{job_id}] ğŸš€ Sent to {target}: {content}")

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python -m ai_masa.agents.base_agent <Name> <Description> [user_lang] [llm_command] [llm_session_create_command]")
        sys.exit(1)
    
    agent = BaseAgent(
        name=sys.argv[1],
        description=sys.argv[2],
        user_lang=sys.argv[3] if len(sys.argv) > 3 else 'Japanese',
        llm_command=sys.argv[4] if len(sys.argv) > 4 else "echo '{\"to_agent\": \"dummy\", \"content\": \"dummy response\"}'",
        llm_session_create_command=sys.argv[5] if len(sys.argv) > 5 else "echo 'new_session_id'"
    )
    agent.observe_loop()